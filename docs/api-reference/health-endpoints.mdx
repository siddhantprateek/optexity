---
title: Health Endpoints
description: Monitor inference server status and task execution
---

The inference server exposes health check endpoints for monitoring and orchestration.

## GET /health

Check server health and task queue status.

### Request

```bash
GET http://localhost:9000/health
```

### Response

#### Healthy (200 OK)

```json
{
  "status": "healthy",
  "task_running": false,
  "queued_tasks": 0
}
```

#### Unhealthy (503 Service Unavailable)

```json
{
  "status": "unhealthy",
  "message": "Task running for more than 15 minutes",
  "task_running": true,
  "queued_tasks": 2
}
```

### Response Fields

<ParamField path="status" type="'healthy' | 'unhealthy'">
  Overall server health status.
</ParamField>

<ParamField path="task_running" type="bool">
  Whether a task is currently executing.
</ParamField>

<ParamField path="queued_tasks" type="int">
  Number of tasks waiting in the queue.
</ParamField>

<ParamField path="message" type="str" optional>
  Additional information when unhealthy.
</ParamField>

### Health Criteria

The server is considered **unhealthy** when:

- A task has been running for more than 15 minutes without completing

This indicates a potential stuck automation that may need intervention.

### Example

```bash
# Check health
curl http://localhost:9000/health

# Response when idle
# {"status": "healthy", "task_running": false, "queued_tasks": 0}

# Response when processing
# {"status": "healthy", "task_running": true, "queued_tasks": 1}

# Response when stuck
# {"status": "unhealthy", "message": "Task running for more than 15 minutes", "task_running": true, "queued_tasks": 0}
```

---

## GET /is_task_running

Simple check for whether a task is currently executing.

### Request

```bash
GET http://localhost:9000/is_task_running
```

### Response

```json
true
```

or

```json
false
```

### Example

```bash
curl http://localhost:9000/is_task_running
# true
```

---

## Use Cases

### Load Balancing

Use `/health` to route traffic away from busy or stuck workers:

```python
import requests

def is_worker_available(host: str) -> bool:
    try:
        response = requests.get(f"{host}/health", timeout=5)
        if response.status_code != 200:
            return False
        data = response.json()
        return data["status"] == "healthy" and not data["task_running"]
    except:
        return False
```

### Queue Monitoring

Monitor queue depth across workers:

```python
import requests

def get_queue_stats(hosts: list[str]) -> dict:
    stats = {"total_queued": 0, "running": 0, "available": 0}
    
    for host in hosts:
        try:
            response = requests.get(f"{host}/health", timeout=5)
            data = response.json()
            stats["total_queued"] += data.get("queued_tasks", 0)
            if data.get("task_running"):
                stats["running"] += 1
            else:
                stats["available"] += 1
        except:
            pass
    
    return stats
```

### Alerting

Set up alerts for unhealthy workers:

```python
import requests

def check_and_alert(hosts: list[str]):
    for host in hosts:
        try:
            response = requests.get(f"{host}/health", timeout=5)
            if response.status_code == 503:
                data = response.json()
                send_alert(f"Worker {host} unhealthy: {data.get('message')}")
        except requests.RequestException as e:
            send_alert(f"Worker {host} unreachable: {e}")
```

### Waiting for Task Completion

Poll until a worker becomes available:

```python
import time
import requests

def wait_for_available(host: str, timeout: int = 300) -> bool:
    start = time.time()
    while time.time() - start < timeout:
        try:
            response = requests.get(f"{host}/is_task_running", timeout=5)
            if not response.json():
                return True
        except:
            pass
        time.sleep(5)
    return False
```

---

## AWS/ECS Mode

When running with `is_aws=True`, additional endpoints are available:

### POST /allocate_task

Directly allocate a task (used by orchestrator):

```bash
POST http://worker:9000/allocate_task
Content-Type: application/json

{
  "task_id": "...",
  "automation": {...},
  ...
}
```

### POST /set_child_process_id

Set the worker's child process ID:

```bash
POST http://worker:9000/set_child_process_id
Content-Type: application/json

{
  "child_process_id": 1
}
```

---

## Related

- [Inference Endpoint](/api-reference/inference-endpoint) - Submit tasks
- [Getting Started Guide](/docs/getting-started) - Server setup

